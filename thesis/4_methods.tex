\section{Methods}

\subsection{Setup}

The workstation for this study included an Intel i5 processor, 16GB of RAM and most importantly a NVidia Geforce GTX1060/6GB. Neural Networks can be trained more effienctly on GPUs than CPUs. This is because the simpler but highly parallized architecture of graphics chips plays in favor for the needed calculations in deep learning.

The workstation ran Ubuntu 16.04 with the CUDA and cuDNN libraries installed in order to take advantage of the GPU. As the main programming language Python was chosen due to its simple syntax and popularity in the deep learning field. Keras was chosen as the framework for training models, because its top level syntax allows fast prototyping and testing. SimpleITK is a Python binding of ITK library written in C++. It includes many tools for image processing and is especially popular in the medical field, where it originated.

\subsection{Data Analysis}

The dataset was a collection of three dimensional MR images showing human knees. The number of available samples grew during the project. For most of the development time it included 150 images that came from 3 different sources.

\begin{table}[h!]
\centering
\begin{tabular}{l l l r r l}
    Source & Prospective & Perspective & Samples & Maps & Resolution \\
    \hline
    Epi    & Yes         & Coronal     & 80      & 40   & 800x800x41 \\
    Jopp   & No          & Coronal     & 65      & 36   & 512x512x24 \\
    Maas   & No          & Sagittal    & 5       & 0    & multiple \\
\end{tabular}
\caption{Details of available images sorted by their source}
\end{table}



3d, mri, german males, 14-21, different resolutions, coronal/sagittal, segmentation maps for 76, mhd files, distribution of age.



\subsection{Preprocessing}

The number of parameters in a Neural Network commonly range from hundreds of thousands to hundreds of millions. This complexity allows the model to learn on its own what features of an image are relevant for any given task. It works in conjunction with the fact that high volumes of data are available for the training.

Because of the small dataset that was available for this study, several types of data preprocessing were applied to the images. These techniques do one of three things:

\begin{itemize}
\item Decrease the amount of information per sample
\item Decrease the variance between multiple samples
\item Increase the total number of samples
\end{itemize}

Other preprocessing methods experimented with the difference between 2D and 3D data as well as the influence of separate segmentation channels on the output.

\subsubsection{Cropping and Resizing}

The framing of the raw images included large parts of the thigh and shin to be visible in the picture. Since these weren't relevant for the purpose of the study, they were cropped out. An algorithm was used to detect the center where Tibia and Femur meet and only use a square window around this point. There was no cropping applied on the z-axis.

The images were also resized to a resolution that is common for Convolutional Neural Networks. 224x224 Pixels for width and height also allowed the use of Transfer Learning based on popular pre-trained models. This resolution still delivered enough detail for the segmentation maps.

On the z-axis everything was scaled to 36 slices, which meant a 1.5 upscale for the images provided by Jopp et al. and a minor downscale from the 41 slices that were taken specifically for this study.

Every image now had unified dimensions of 36x224x224 voxels.

\subsubsection{Normalization}

The normalization procedure of this dataset was executed in two steps. First the N4 Bias Correction was applied to the images, which tries to balance irregularities than happen when the MRIs were recorded. In the second step all intensity values were normalized to range from 0 to 1 so that every input is on the same scale.

\subsubsection{Bias Field Correction}

text

\subsubsection{Augmentation}

text

\subsubsection{2D and 3D data}

Every three dimensional image can be converted to n two dimensional slices, where n is the resolution of the sliced axis. Since the z-axis shows a much lower resolution than x and y, each image was sliced in 36 224x224 2D images. This resulted in 36 times more samples, but reduced the information per image by the same factor. 

Using three dimensional convolutions turned out to be helpful for the segmentation, because the network was able to draw conclusions from the order of the slices within one image. 

\subsubsection{Separate Bone Maps}

The initial segmentation maps included three separate channels for the differentiation between the Tibia, Femur and Fibula. 

The initial segmentation maps came with three separate channels for the Femur, Tibia and Fibula. With this information it was possible to train a model that would segment the three bones while still differentiating between them. This helped the accuracy of the prediction opposed to using just a single channel for all of the bones. In places where the Femur and Tibia were very close to one another, the separate channels prevented the closing of this region by the network.

For another experiment the three channels were treated as one to create a network that would segment any type of bone in the image. This resulted in better performance when applied to sagittal images of the knee provided by Maas et al. The network was able to generalize on a situation it wasn't trained on.

\subsection{Architecture}



In search for a network that would perform well on the segmentation, different architectures were looked at and multiple settings were tried.

\subsubsection{Patch and Image based}

As described in 3.2.2 the segmentation of an image can be seen as the classification of every pixel or voxel


\subsubsection{Channels}

growth and initial size

\subsubsection{Dropout}

Dropout is a popular regularization technique that randomly zeros out a fraction of the weights during training. It is understood that this helps the model to generalize better and reduce overfitting on a given dataset. Well known image classification architectures like VGG16, SqueezeNet or AlexNet use Dropout near the end of the network. Similarly U-Net uses Dropout at the end of the contracting path of the architecture to implicitly add image augmentation to the data. The original paper does not give any information how much Dropout was used.

Since overfitting was a big problem of this study, several other Dropout strategies were investigated. Increasing the rate above 0.5 did reduce the overfitting, but also hurt the performance of the model. Placing a Dropout unit between each convolution pair on the contracting side turned out to be an effective method for this dataset. Multiple amounts of Dropout were tested of which 0.2 achieved the best results. 0.1 resulted is more overfitting and 0.3 led to instabilities during training.

While it didn't hurt the performance when low amounts of Dropout were also added to the expanding side, it had a negative effect on the training speed. We believe this is due to the nature of an encoding/decoding architecture. On the contracting side of the network the amount of information is compressed by decreasing the spatial resolution of the images. This dense representation can lead to overfitting because the number of features is heavily reduced from the input. The upscaling side of the model expands the available information, which helps to fight overfitting on its own.


\subsubsection{Batch Size}

Neural Networks use a process called stochastic gradient descent (SGD) or one of its variants to approximate the gradient on a small fraction of the data. The size of this fraction is called the batch size and describes how many samples are used for a single forward- and back-propagation step.

In the past it was believed that larger batches led to something called the generalization gap (1609.04836), where the accuracy of a model would drop if it was trained on particularly large batches. Recent work by Hoffer at al. (1705.08741) suggests other reasons for this drop in accuracy. While common batch sizes range from 32 to 256, Goyal et al. showed accurate results using 8192 images per batch when training a model on imagenet (1706.02677).

Depending on the size of the input one may be restricted to smaller batches. In the field of 3D convolutions even one image can take up a majority of the RAM on a workstation.

\subsection{Training}

The training phase describes the actual learning process of the architecture. After initializing the neural network with random values, several parameters have an influence on the accuracy of the model and how quickly a possible optimum is reached.

\subsubsection{Training, Validation and Testing}

In order to measure how well a network generalizes on samples it hasn't seen before, the dataset was split up in a training and validation portion. While 80 percent of the data was reserved to make the model learn, the remaining 20 percent were used to measure the results.

In larger datasets it is common to use another fraction of the data as the Test Set, which is used as a second level validation method. By using the validation data multiple times throughout the training, the network may get an implicit view of its content. The test set can then be applied at the very end to measure the final accuracy of the model.

\subsubsection{Loss Function and Metrics}

The loss function measures the performance on a single batch and its result is what the network will minimise during the back-propagation. Common choices include the mean squared error (MSE) for regression problems or the categorical cross entropy (CCE) for classification problems. 

For segmentation purposes there are other units of measure that give more intuition about the performance of the model. These include the Intersection-over-Union (IoU) or the DICE coefficient. 

--insert formulas--

Both describe the overlap of ground truth and prediction in relation to falsely identified segments. Higher scores of these measurements indicate a better segmentation. Since the back-propagation will minimise the result of the loss function, the negative DICE coefficient was used for this study.

\subsubsection{Optimizer}

The optimizer 

\subsubsection{Learning Rate Policy}

The learning rate policy describes how the learning rate is changed throughout the training. With the introduction of adaptive optimizers like Adam or RMSProp there has been a lower emphasize on this topic. Learning rates that were set too high or too low, will be adjusted by the optimizer after a few iterations. Even though this reduces the number of possible defects, a lot of training time can be saved with the right policy.

10 epochs were run at different learning rates to compare initial results and to examine the point at which the model wouldn't converge at all. 0.002 was the highest rate at which the model started training, but 0.001 resulted in the best score.

After the model stopped to improve at epoch 65 the learning rate was changed to 0.0001. This gave a small boost of accuracy. In order to have a smooth transition between learning rates, the decay was set to 0.001. This meant that the initial learning rate of 0.001 would reach 0.0001 after 68 epochs.

-- insert training time graph --

\subsubsection{Early Stopping}

Neural networks will continuously minimise the loss on the training set. This result needs to be validated on data the network hasn't seen before. At a certain point during training the performance on the validation set will start to decrease, because the model is over fitting on the training data. The number of iterations to reach this point is dependent on many hyperparameters, as well as the random values the network as been initialised with. As such it's difficult to calculate how many epochs the training will need to reach its peak.

Early stopping is a simple technique that will end the training process as soon as the model stops improving on the validation data. In order to do this, a patience is defined how long the network should continue training after the score has gone down. This is important because not every epoch will lead to a new best score on the validation data.

For test runs in this study a patience of 9 was selected, which meant the training would stop after 10 epochs without improvement. Depending on the architecture and other hyperparameters this point was reached after 30 to 60 epochs. For the last training with the final set of hyperparameters the patience was increased to 19, which didn't improve the accuracy.  This was also a verification that the initial value of 9 was a good fit for this problem.



\newpage
