{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Imports & global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import dask.array as da\n",
    "from dask.array.image import imread\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from glob import glob\n",
    "import skimage.io as skio\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dim = (192,192,1)\n",
    "out_dim = 3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def smart_crop(path, size):\n",
    "    files = glob(path)\n",
    "    for i in tqdm(range(len(files))):\n",
    "        img = skio.imread(files[i], as_grey=True)\n",
    "        if img.shape[0] > size:\n",
    "            arr = np.where(img.sum(axis=0) > 0)[0]\n",
    "            x_c = (arr[0]+arr[-1])//2\n",
    "            arr = np.where(img.sum(axis=1) > 0)[0]\n",
    "            y_c = (arr[0]+arr[-1])//2\n",
    "            img = img[y_c-size//2:y_c+size//2, x_c-size//2:x_c+size//2]\n",
    "            skio.imsave(files[i], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labels(arr):\n",
    "    labels = []\n",
    "    for i in range(len(arr)):\n",
    "        proto = np.zeros(len(arr))\n",
    "        proto[i] = 1\n",
    "        for j in range(arr[i]):\n",
    "            labels.append(proto)\n",
    "    return da.from_array(np.array(labels), chunks=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Preprocess Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original images are 500x500 pixel with lots of unused space. The content however, isnt perfectly centered, so i defined a smart crop function that analyses the content of each image and crops around the actual content based center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [00:00<00:00, 1743.94it/s]\n",
      "100%|██████████| 110/110 [00:00<00:00, 1767.67it/s]\n",
      "100%|██████████| 75/75 [00:00<00:00, 1786.18it/s]\n"
     ]
    }
   ],
   "source": [
    "smart_crop('data/train/*/*.jpg', in_dim[0])\n",
    "smart_crop('data/validation/*/*.jpg', in_dim[0])\n",
    "smart_crop('data/test/*.jpg', in_dim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (566, 192, 192) (566, 3)\n",
      "Validation: (110, 192, 192) (110, 3)\n",
      "Test: (75, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "x_tr = imread('data/train/*/*.jpg')\n",
    "y_tr = create_labels([222,174,170])\n",
    "print(\"Train:\", x_tr.shape, y_tr.shape)\n",
    "\n",
    "x_va = imread('data/validation/*/*.jpg')\n",
    "y_va = create_labels([39,38,33])\n",
    "print(\"Validation:\", x_va.shape, y_va.shape)\n",
    "\n",
    "x_te = imread('data/test/*.jpg')\n",
    "print(\"Test:\", x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr = x_tr / 255.\n",
    "x_tr = x_tr[..., np.newaxis]\n",
    "\n",
    "x_va = x_va / 255.\n",
    "x_va = x_va[..., np.newaxis]\n",
    "\n",
    "x_te = x_te / 255.\n",
    "x_te = x_te[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(y_tr))\n",
    "x_tr = x_tr[perm]\n",
    "y_tr = y_tr[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr.astype('float16').to_hdf5('data/x_tr.h5', 'x_tr')\n",
    "y_tr.astype('uint8').to_hdf5('data/y_tr.h5', 'y_tr')\n",
    "\n",
    "x_va.astype('float16').to_hdf5('data/x_va.h5', 'x_va')\n",
    "y_va.astype('uint8').to_hdf5('data/y_va.h5', 'y_va')\n",
    "\n",
    "x_te.astype('float16').to_hdf5('data/x_te.h5', 'x_te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr = da.from_array(h5py.File('data/x_tr.h5')['x_tr'], chunks=1000)\n",
    "y_tr = da.from_array(h5py.File('data/y_tr.h5')['y_tr'], chunks=10000)\n",
    "\n",
    "x_va = da.from_array(h5py.File('data/x_va.h5')['x_va'], chunks=1000)\n",
    "y_va = da.from_array(h5py.File('data/y_va.h5')['y_va'], chunks=10000)\n",
    "\n",
    "x_te = da.from_array(h5py.File('data/x_te.h5')['x_te'], chunks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=0.1,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.1,\n",
    "                         zoom_range=0.2,\n",
    "                         horizontal_flip=True)\n",
    "train_gen = gen.flow(x_tr, y_tr, batch_size=batch_size)\n",
    "gen = ImageDataGenerator()\n",
    "valid_gen = gen.flow(x_va, y_va, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 192, 192, 1)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 192, 192, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 192, 192, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 96, 96, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 96, 96, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 48, 48, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 48, 48, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 6, 6, 16)          1040      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 96,023\n",
      "Trainable params: 96,021\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "i = Input(shape=in_dim)\n",
    "m = BatchNormalization()(i)\n",
    "m = Conv2D(16, 3, activation='elu', padding='same')(m)\n",
    "m = Conv2D(16, 3, activation='elu', padding='same', strides=2)(m)\n",
    "m = Conv2D(16, 3, activation='elu', padding='same')(m)\n",
    "m = Conv2D(16, 3, activation='elu', padding='same', strides=2)(m)\n",
    "m = Conv2D(32, 3, activation='elu', padding='same')(m)\n",
    "m = Conv2D(32, 3, activation='elu', padding='same', strides=2)(m)\n",
    "m = Conv2D(32, 3, activation='elu', padding='same')(m)\n",
    "m = Conv2D(32, 3, activation='elu', padding='same', strides=2)(m)\n",
    "m = Conv2D(64, 3, activation='elu', padding='same')(m)\n",
    "m = Conv2D(64, 3, activation='elu', padding='same', strides=2)(m)\n",
    "m = Conv2D(16, 1, activation='elu', padding='same')(m)\n",
    "m = GlobalAveragePooling2D()(m)\n",
    "o = Dense(out_dim, activation='softmax')(m)\n",
    "\n",
    "model = Model(inputs=i, outputs=o)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 15s - loss: 0.9873 - acc: 0.4692 - val_loss: 0.8426 - val_acc: 0.4636\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 14s - loss: 0.5121 - acc: 0.7439 - val_loss: 0.4512 - val_acc: 0.7455\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 14s - loss: 0.3818 - acc: 0.8150 - val_loss: 0.3815 - val_acc: 0.7727\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 14s - loss: 0.3446 - acc: 0.8384 - val_loss: 0.3239 - val_acc: 0.8182\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 14s - loss: 0.3108 - acc: 0.8596 - val_loss: 0.2526 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 14s - loss: 0.2734 - acc: 0.8767 - val_loss: 0.2548 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 14s - loss: 0.2533 - acc: 0.8913 - val_loss: 0.2331 - val_acc: 0.8909\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 14s - loss: 0.2418 - acc: 0.8964 - val_loss: 0.1688 - val_acc: 0.9182\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 14s - loss: 0.2284 - acc: 0.9026 - val_loss: 0.2661 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 14s - loss: 0.2202 - acc: 0.9058 - val_loss: 0.2953 - val_acc: 0.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136e94048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, validation_data=(x_va, y_va), epochs=10, steps_per_epoch=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_8818_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5 Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:00<00:00, 1807.92it/s]\n"
     ]
    }
   ],
   "source": [
    "smart_crop('data/test/*.jpg', in_dim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = imread('data/test/*.jpg')\n",
    "test = test / 255.\n",
    "test = test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model_9376')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_te)\n",
    "pred = pred.argmax(axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs = sorted(glob('data/test/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = pd.Series(test_imgs)\n",
    "t2 = pd.Series(pred)\n",
    "df = pd.concat([t1, t2], axis=1, keys=['File', 'Class'])\n",
    "df.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
